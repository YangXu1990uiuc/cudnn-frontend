{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Norm with Pointwise Add\n",
    "\n",
    "This notebook shows how to compute forward pointwise add + layer normalization with intermediate output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVIDIA/cudnn-frontend/blob/main/samples/python/25_layernorm_forward_training_and_backward_with_relu_bitmask.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites and Setup\n",
    "This notebook requires an NVIDIA GPU. If `nvidia-smi` fails, go to Runtime -> Change runtime type -> Hardware accelerator and confirm a GPU is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_ipython().system('nvidia-smi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running on Colab, you will need to install the cudnn python interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_ipython().system('pip install nvidia-cudnn-cu12')\n",
    "# get_ipython().system('pip install nvidia-cudnn-frontend')\n",
    "# get_ipython().system('pip3 install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu128')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will apply layer norm to a tensor of the following shape:\n",
    "\n",
    "- Batch Size: 4\n",
    "- Sequence Size: 1024\n",
    "- Embedding Dimension: 768\n",
    "\n",
    "Let's define these dimensions as constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudnn\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(1)\n",
    "handle = cudnn.create_handle()\n",
    "\n",
    "print(\"Running with cudnn backend version:\", cudnn.backend_version())\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "assert (\n",
    "    cudnn.backend_version() >= 91400\n",
    "), \"LayerNorm pointwise fusion with intermediate output is only supported cuDNN version 9.14.0 or above\"\n",
    "\n",
    "batch, seq_size, embedding_dim = 4, 1024, 768\n",
    "dtype = torch.float32\n",
    "\n",
    "# Epsilon is a small number to prevent division by 0.\n",
    "epsilon_value = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add and LayerNorm with Intermediate bfloat16 Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the input tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate random input tensors\n",
    "x_gpu = torch.randn(\n",
    "    batch * seq_size, embedding_dim, 1, 1, device=\"cuda\", dtype=dtype\n",
    ").to(memory_format=torch.channels_last)\n",
    "add_gpu = torch.randn(\n",
    "    batch * seq_size, embedding_dim, 1, 1, device=\"cuda\", dtype=dtype\n",
    ").to(memory_format=torch.channels_last)\n",
    "scale_gpu = torch.randn(1, embedding_dim, 1, 1, device=\"cuda\", dtype=dtype).to(\n",
    "    memory_format=torch.channels_last\n",
    ")\n",
    "bias_gpu = torch.randn(1, embedding_dim, 1, 1, device=\"cuda\", dtype=dtype).to(\n",
    "    memory_format=torch.channels_last\n",
    ")\n",
    "epsilon_cpu = torch.full((1, 1, 1, 1), epsilon_value, dtype=torch.float32, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the graph for the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cudnn.Graph(\n",
    "    io_data_type=cudnn.data_type.FLOAT,\n",
    "    intermediate_data_type=cudnn.data_type.BFLOAT16,\n",
    "    compute_data_type=cudnn.data_type.FLOAT,\n",
    ") as fwd_graph:\n",
    "    # pointwise add operation: x + b\n",
    "    added_x = fwd_graph.add(\n",
    "        name=\"Pointwise add\",\n",
    "        a=x_gpu,\n",
    "        b=add_gpu,\n",
    "    )\n",
    "    # layernorm forward pass\n",
    "    out, mean, inv_var = fwd_graph.layernorm(\n",
    "        name=\"LN\",\n",
    "        norm_forward_phase=cudnn.norm_forward_phase.TRAINING,\n",
    "        input=added_x,\n",
    "        scale=scale_gpu,\n",
    "        bias=bias_gpu,\n",
    "        epsilon=epsilon_cpu,\n",
    "    )\n",
    "    # mark the output tensors\n",
    "    added_x.set_name(\"added_x\").set_output(True).set_data_type(cudnn.data_type.BFLOAT16)\n",
    "    out.set_name(\"output\").set_output(True).set_data_type(cudnn.data_type.FLOAT)\n",
    "    mean.set_name(\"mean\").set_output(True).set_data_type(cudnn.data_type.FLOAT)\n",
    "    inv_var.set_name(\"inv_var\").set_output(True).set_data_type(cudnn.data_type.FLOAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, execute the graph and compare the output to the reference output from PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocated output tensors\n",
    "added_x_gpu = torch.empty(\n",
    "    batch * seq_size, embedding_dim, 1, 1, dtype=torch.bfloat16, device=\"cuda\"\n",
    ")\n",
    "out_gpu = torch.empty_like(x_gpu)\n",
    "mean_gpu = torch.empty(batch * seq_size, 1, 1, 1, dtype=torch.float32, device=\"cuda\")\n",
    "inv_var_gpu = torch.empty(batch * seq_size, 1, 1, 1, dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "# execute the graph\n",
    "output = fwd_graph(\n",
    "    {\n",
    "        # input tensors\n",
    "        \"Pointwise add::a\": x_gpu,\n",
    "        \"Pointwise add::b\": add_gpu,\n",
    "        \"LN::scale\": scale_gpu,\n",
    "        \"LN::bias\": bias_gpu,\n",
    "        \"LN::epsilon\": epsilon_cpu,\n",
    "        # output tensors\n",
    "        \"added_x\": added_x_gpu,\n",
    "        \"output\": out_gpu,\n",
    "        \"mean\": mean_gpu,\n",
    "        \"inv_var\": inv_var_gpu,\n",
    "    },\n",
    "    handle=handle,\n",
    ")\n",
    "\n",
    "# PyTorch reference forward operation with intermediate bfloat16 output\n",
    "added_x_ref = torch.add(x_gpu, add_gpu).to(torch.bfloat16)\n",
    "out_ref = torch.nn.functional.layer_norm(\n",
    "    added_x_ref.to(torch.float32),\n",
    "    [embedding_dim, 1, 1],\n",
    "    weight=scale_gpu.squeeze(0),\n",
    "    bias=bias_gpu.squeeze(0),\n",
    "    eps=epsilon_value,\n",
    ")\n",
    "mean_ref = added_x_ref.to(torch.float32).mean(dim=(1, 2, 3), keepdim=True)\n",
    "inv_var_ref = torch.rsqrt(\n",
    "    torch.var(added_x_ref.to(torch.float32), dim=(1, 2, 3), keepdim=True)\n",
    "    + epsilon_value\n",
    ")\n",
    "\n",
    "# compare to reference output\n",
    "torch.testing.assert_close(added_x_gpu, added_x_ref, rtol=5e-3, atol=5e-3)\n",
    "torch.testing.assert_close(out_gpu, out_ref, rtol=5e-3, atol=5e-3)\n",
    "torch.testing.assert_close(inv_var_gpu, inv_var_ref, rtol=5e-3, atol=5e-3)\n",
    "torch.testing.assert_close(mean_gpu, mean_ref, rtol=5e-3, atol=5e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
